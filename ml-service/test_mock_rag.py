import os
import shutil
import sys
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
try:
    from langchain_community.vectorstores import Chroma
    CHROMA_AVAILABLE = True
except ImportError:
    CHROMA_AVAILABLE = False
except Exception as e:
    # Catching the LRScheduler or other library loading errors
    print(f"Warning: Could not load ChromaDB ({e}). Using Mock Retriever.")
    CHROMA_AVAILABLE = False

from langchain_community.embeddings import FakeEmbeddings
from langchain_community.llms import FakeListLLM
from langchain.chains import RetrievalQA
from langchain.schema import Document

# Constants
VECTOR_DB_PATH = "./test_chroma_db"
COLLECTION_NAME = "test_collection"

def test_rag_flow():
    print("=== Testing RAG Flow ===")
    
    # 1. Setup Mock Components
    print("[1/3] Initializing components...")
    embeddings = FakeEmbeddings(size=1536)
    llm = FakeListLLM(responses=["This is a mock response based on the context of the museum."])
    
    # 2. Ingest Data
    print("[2/3] Ingesting data...")
    if os.path.exists("sample_data.txt"):
        loader = TextLoader("sample_data.txt")
        documents = loader.load()
    else:
        documents = [Document(page_content="The King's Palace Museum is located in Nyanza.", metadata={"source": "mock"})]

    text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)
    texts = text_splitter.split_documents(documents)
    
    # 3. Vector Search & Query
    print("[3/3] Querying...")
    
    if CHROMA_AVAILABLE:
        try:
            # Clean up previous test run
            if os.path.exists(VECTOR_DB_PATH):
                shutil.rmtree(VECTOR_DB_PATH)
                
            vector_db = Chroma.from_documents(
                documents=texts, 
                embedding=embeddings,
                persist_directory=VECTOR_DB_PATH,
                collection_name=COLLECTION_NAME
            )
            vector_db.persist()
            retriever = vector_db.as_retriever(search_kwargs={"k": 1})
            print(" -> Using ChromaDB Vector Store")
        except Exception as e:
            print(f" -> ChromaDB init failed ({e}). Falling back to dummy retrieval.")
            retriever = None
    else:
        print(" -> ChromaDB unavailable. Falling back to dummy retrieval.")
        retriever = None

    if retriever:
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=retriever
        )
        query = "What is this text about?"
        response = qa_chain.run(query)
    else:
        # Mock retrieval if DB fails
        query = "What is this text about?"
        response = llm.predict(query)
        print(" -> (Simulated RAG response without vector store)")

    print(f"\nUser Query: {query}")
    print(f"AI Response: {response}")
    
    # Cleanup
    if CHROMA_AVAILABLE and os.path.exists(VECTOR_DB_PATH):
        try:
            shutil.rmtree(VECTOR_DB_PATH)
        except:
            pass
            
    print("\nâœ… Test completed successfully.")

if __name__ == "__main__":
    test_rag_flow()
